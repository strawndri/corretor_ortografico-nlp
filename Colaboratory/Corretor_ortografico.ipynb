{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Corretor_ortografico.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNoraS5IL1b0zALTmYXViCn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/strawndri/corretor_ortografico-nlp/blob/main/Colaboratory/Corretor_ortografico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w69e3gSa-N_o"
      },
      "source": [
        "# NLP - Processamento de Linguagem Natural\n",
        "\n",
        "A **Processamento de Linguagem Natural (NLP, em inglês)** está relacionada à Inteligência Antificial. Este mecanismo, portanto, atua na conexão entre o ser humano e a máquina.\n",
        "\n",
        "A interpretação de textos realizada por pessoas, é de certa forma, simples. No entanto, quando este papel cabe à máquina, a situação torna-se mais complicada, uma vez que ela precisa \"compreender\" inúmeros peculiaridades linguísticas, como coensão, coêrencia, morfologia, semântica, sintaxe, etc.\n",
        "\n",
        "Alguns exemplos de atividades comuns que utlizam o NLP são: tradução automática, corretor ortográfico, autocomplete (realizado pelo Google, por exemplo), chatbots..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5JsbWliEYtr"
      },
      "source": [
        "# Importando um Corpus Textual\n",
        "Obs: Corpus significa, em NLP, uma coleção de documentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5Ybtyvq-MEo",
        "outputId": "a217f9c5-97c9-4819-aba4-3f9631e8ffd4"
      },
      "source": [
        "with open('artigos.txt', 'r') as f:\n",
        "  artigos = f.read()\n",
        "\n",
        "print(artigos[:500])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "imagem \n",
            "\n",
            "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
            "\n",
            "java\n",
            "\n",
            "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
            "\n",
            "java \n",
            "\n",
            "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sph_FqBJZm-3"
      },
      "source": [
        "# Tokens\n",
        "\n",
        "Os **tokens** são uma sequência de caracteres (podem conter letras, números, pontuações, etc) separados por um limitador, que pode ser tanto um espaço em branco, como uma quebra de linha ou determinada pontuação).\n",
        "\n",
        "**Tozenização** é um processo que divide strings em partes menores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAlLvXkcE7sW",
        "outputId": "68879902-8093-4685-e4d0-4f922b988d80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokens = artigos.split()\n",
        "print(f'Quantidade de tokens: {len(tokens)}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de tokens: 416903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzxg5RmMa5tz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}